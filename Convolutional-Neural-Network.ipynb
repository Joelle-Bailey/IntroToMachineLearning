{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e86d13f2",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "by Joelle Bailey for ECGR 4105 800984146"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "363ca21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bf4e821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "data_path = '/data-unversioned/p1ch7/'\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c3bc151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.cifar.CIFAR10"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef299ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t, _ = cifar10[99]\n",
    "type(img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9027c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_t, _ = cifar10[99]\n",
    "\n",
    "plt.imshow(img_t.permute(1, 2, 0)) # Need to rearrage for printing\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b73a50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_out = 10\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.LogSoftmax(dim =1)\n",
    ")\n",
    "\n",
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36585037",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64d34674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training Loss 1.752804\n",
      "Epoch 2, Training Loss 1.575360\n",
      "Epoch 4, Training Loss 1.099887\n",
      "Epoch 6, Training Loss 1.138529\n",
      "Epoch 8, Training Loss 1.315857\n",
      "Epoch 10, Training Loss 1.891225\n",
      "Epoch 12, Training Loss 1.490237\n",
      "Epoch 14, Training Loss 0.412081\n",
      "Epoch 16, Training Loss 1.098441\n",
      "Epoch 18, Training Loss 1.057772\n",
      "Epoch 20, Training Loss 1.487097\n",
      "Epoch 22, Training Loss 0.955058\n",
      "Epoch 24, Training Loss 0.834943\n",
      "Epoch 26, Training Loss 0.408199\n",
      "Epoch 28, Training Loss 0.459710\n",
      "Epoch 30, Training Loss 0.396547\n",
      "Epoch 32, Training Loss 0.425056\n",
      "Epoch 34, Training Loss 0.923534\n",
      "Epoch 36, Training Loss 0.471935\n",
      "Epoch 38, Training Loss 0.417362\n",
      "Epoch 40, Training Loss 0.341376\n",
      "Epoch 42, Training Loss 0.345548\n",
      "Epoch 44, Training Loss 0.581854\n",
      "Epoch 46, Training Loss 0.403462\n",
      "Epoch 48, Training Loss 0.332754\n",
      "Epoch 50, Training Loss 0.188427\n",
      "Epoch 52, Training Loss 0.195487\n",
      "Epoch 54, Training Loss 0.081002\n",
      "Epoch 56, Training Loss 0.216723\n",
      "Epoch 58, Training Loss 0.223697\n",
      "Epoch 60, Training Loss 0.095659\n",
      "Epoch 62, Training Loss 0.065884\n",
      "Epoch 64, Training Loss 0.054776\n",
      "Epoch 66, Training Loss 0.037271\n",
      "Epoch 68, Training Loss 0.151660\n",
      "Epoch 70, Training Loss 0.080072\n",
      "Epoch 72, Training Loss 0.028866\n",
      "Epoch 74, Training Loss 0.043749\n",
      "Epoch 76, Training Loss 0.061187\n",
      "Epoch 78, Training Loss 0.118348\n",
      "Epoch 80, Training Loss 0.017965\n",
      "Epoch 82, Training Loss 0.044391\n",
      "Epoch 84, Training Loss 0.041361\n",
      "Epoch 86, Training Loss 0.030974\n",
      "Epoch 88, Training Loss 0.081427\n",
      "Epoch 90, Training Loss 0.058035\n",
      "Epoch 92, Training Loss 0.019183\n",
      "Epoch 94, Training Loss 0.017589\n",
      "Epoch 96, Training Loss 0.025086\n",
      "Epoch 98, Training Loss 0.016374\n",
      "Epoch 100, Training Loss 0.019496\n",
      "Epoch 102, Training Loss 0.010793\n",
      "Epoch 104, Training Loss 0.022980\n",
      "Epoch 106, Training Loss 0.010454\n",
      "Epoch 108, Training Loss 0.031651\n",
      "Epoch 110, Training Loss 0.017900\n",
      "Epoch 112, Training Loss 0.011467\n",
      "Epoch 114, Training Loss 0.017799\n",
      "Epoch 116, Training Loss 0.021377\n",
      "Epoch 118, Training Loss 0.020780\n",
      "Epoch 120, Training Loss 0.013857\n",
      "Epoch 122, Training Loss 0.028740\n",
      "Epoch 124, Training Loss 0.016269\n",
      "Epoch 126, Training Loss 0.007010\n",
      "Epoch 128, Training Loss 0.010092\n",
      "Epoch 130, Training Loss 0.010762\n",
      "Epoch 132, Training Loss 0.006141\n",
      "Epoch 134, Training Loss 0.008162\n",
      "Epoch 136, Training Loss 0.022056\n",
      "Epoch 138, Training Loss 0.008569\n",
      "Epoch 140, Training Loss 0.007516\n",
      "Epoch 142, Training Loss 0.007079\n",
      "Epoch 144, Training Loss 0.010489\n",
      "Epoch 146, Training Loss 0.006391\n",
      "Epoch 148, Training Loss 0.013832\n",
      "Epoch 150, Training Loss 0.011871\n",
      "Epoch 152, Training Loss 0.006222\n",
      "Epoch 154, Training Loss 0.007808\n",
      "Epoch 156, Training Loss 0.005045\n",
      "Epoch 158, Training Loss 0.008699\n",
      "Epoch 160, Training Loss 0.006125\n",
      "Epoch 162, Training Loss 0.008178\n",
      "Epoch 164, Training Loss 0.005961\n",
      "Epoch 166, Training Loss 0.003842\n",
      "Epoch 168, Training Loss 0.004422\n",
      "Epoch 170, Training Loss 0.020764\n",
      "Epoch 172, Training Loss 0.009230\n",
      "Epoch 174, Training Loss 0.006533\n",
      "Epoch 176, Training Loss 0.004983\n",
      "Epoch 178, Training Loss 0.004988\n",
      "Epoch 180, Training Loss 0.007906\n",
      "Epoch 182, Training Loss 0.005208\n",
      "Epoch 184, Training Loss 0.007694\n",
      "Epoch 186, Training Loss 0.008174\n",
      "Epoch 188, Training Loss 0.003464\n",
      "Epoch 190, Training Loss 0.006939\n",
      "Epoch 192, Training Loss 0.006843\n",
      "Epoch 194, Training Loss 0.005368\n",
      "Epoch 196, Training Loss 0.006276\n",
      "Epoch 198, Training Loss 0.003656\n",
      "Epoch 200, Training Loss 0.008972\n",
      "Epoch 202, Training Loss 0.006967\n",
      "Epoch 204, Training Loss 0.007271\n",
      "Epoch 206, Training Loss 0.004221\n",
      "Epoch 208, Training Loss 0.010347\n",
      "Epoch 210, Training Loss 0.005175\n",
      "Epoch 212, Training Loss 0.010705\n",
      "Epoch 214, Training Loss 0.004736\n",
      "Epoch 216, Training Loss 0.004506\n",
      "Epoch 218, Training Loss 0.003459\n",
      "Epoch 220, Training Loss 0.003371\n",
      "Epoch 222, Training Loss 0.005933\n",
      "Epoch 224, Training Loss 0.004152\n",
      "Epoch 226, Training Loss 0.003180\n",
      "Epoch 228, Training Loss 0.002212\n",
      "Epoch 230, Training Loss 0.003226\n",
      "Epoch 232, Training Loss 0.002111\n",
      "Epoch 234, Training Loss 0.004496\n",
      "Epoch 236, Training Loss 0.006013\n",
      "Epoch 238, Training Loss 0.001835\n",
      "Epoch 240, Training Loss 0.007410\n",
      "Epoch 242, Training Loss 0.003801\n",
      "Epoch 244, Training Loss 0.004726\n",
      "Epoch 246, Training Loss 0.003052\n",
      "Epoch 248, Training Loss 0.007346\n",
      "Epoch 250, Training Loss 0.004196\n",
      "Epoch 252, Training Loss 0.006263\n",
      "Epoch 254, Training Loss 0.004287\n",
      "Epoch 256, Training Loss 0.004520\n",
      "Epoch 258, Training Loss 0.002246\n",
      "Epoch 260, Training Loss 0.003797\n",
      "Epoch 262, Training Loss 0.003398\n",
      "Epoch 264, Training Loss 0.004688\n",
      "Epoch 266, Training Loss 0.004337\n",
      "Epoch 268, Training Loss 0.003860\n",
      "Epoch 270, Training Loss 0.001855\n",
      "Epoch 272, Training Loss 0.004642\n",
      "Epoch 274, Training Loss 0.002558\n",
      "Epoch 276, Training Loss 0.006586\n",
      "Epoch 278, Training Loss 0.002958\n",
      "Epoch 280, Training Loss 0.003325\n",
      "Epoch 282, Training Loss 0.002336\n",
      "Epoch 284, Training Loss 0.002917\n",
      "Epoch 286, Training Loss 0.005045\n",
      "Epoch 288, Training Loss 0.004060\n",
      "Epoch 290, Training Loss 0.003134\n",
      "Epoch 292, Training Loss 0.002933\n",
      "Epoch 294, Training Loss 0.003485\n",
      "Epoch 296, Training Loss 0.002513\n",
      "Epoch 298, Training Loss 0.004495\n",
      "Training finished, took 10246.97s\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 300\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64, shuffle=True)\n",
    "\n",
    "import time\n",
    "training_1hidden_start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for img, label in train_loader:\n",
    "        batch_size = img.shape[0]\n",
    "        out = model(img.view(batch_size,-1))\n",
    "        loss = loss_fn(out, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  #back propagation\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 2 == 0:\n",
    "            print('Epoch %d, Training Loss %f' % (epoch, float(loss)))\n",
    "            \n",
    "print('Training finished, took {:.2f}s'.format(time.time() - training_1hidden_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "860ba605",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), data_path + '1a.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95cb6202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: %f 0.529\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
    "shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\", correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c95daa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_out = 10\n",
    "\n",
    "model2 = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 10),\n",
    "            nn.LogSoftmax(dim =1)\n",
    ")\n",
    "\n",
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fbd5050",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(model2.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0828318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training Loss 1.739498\n",
      "Epoch 2, Training Loss 1.302628\n",
      "Epoch 4, Training Loss 1.139454\n",
      "Epoch 6, Training Loss 0.694356\n",
      "Epoch 8, Training Loss 1.064420\n",
      "Epoch 10, Training Loss 0.783168\n",
      "Epoch 12, Training Loss 0.979610\n",
      "Epoch 14, Training Loss 0.605398\n",
      "Epoch 16, Training Loss 0.882681\n",
      "Epoch 18, Training Loss 0.748953\n",
      "Epoch 20, Training Loss 0.825911\n",
      "Epoch 22, Training Loss 0.324946\n",
      "Epoch 24, Training Loss 0.785077\n",
      "Epoch 26, Training Loss 0.382771\n",
      "Epoch 28, Training Loss 0.276592\n",
      "Epoch 30, Training Loss 0.409464\n",
      "Epoch 32, Training Loss 0.242729\n",
      "Epoch 34, Training Loss 0.186554\n",
      "Epoch 36, Training Loss 0.075788\n",
      "Epoch 38, Training Loss 0.144197\n",
      "Epoch 40, Training Loss 0.034487\n",
      "Epoch 42, Training Loss 0.080850\n",
      "Epoch 44, Training Loss 0.090589\n",
      "Epoch 46, Training Loss 0.039799\n",
      "Epoch 48, Training Loss 0.006188\n",
      "Epoch 50, Training Loss 0.075421\n",
      "Epoch 52, Training Loss 0.004394\n",
      "Epoch 54, Training Loss 0.046092\n",
      "Epoch 56, Training Loss 0.003596\n",
      "Epoch 58, Training Loss 0.014953\n",
      "Epoch 60, Training Loss 0.002682\n",
      "Epoch 62, Training Loss 0.000252\n",
      "Epoch 64, Training Loss 0.002031\n",
      "Epoch 66, Training Loss 0.001580\n",
      "Epoch 68, Training Loss 0.001470\n",
      "Epoch 70, Training Loss 0.002607\n",
      "Epoch 72, Training Loss 0.002210\n",
      "Epoch 74, Training Loss 0.000839\n",
      "Epoch 76, Training Loss 0.000666\n",
      "Epoch 78, Training Loss 0.000901\n",
      "Epoch 80, Training Loss 0.000742\n",
      "Epoch 82, Training Loss 0.001629\n",
      "Epoch 84, Training Loss 0.000655\n",
      "Epoch 86, Training Loss 0.000529\n",
      "Epoch 88, Training Loss 0.000616\n",
      "Epoch 90, Training Loss 0.000709\n",
      "Epoch 92, Training Loss 0.000381\n",
      "Epoch 94, Training Loss 0.000550\n",
      "Epoch 96, Training Loss 0.000531\n",
      "Epoch 98, Training Loss 0.000837\n",
      "Epoch 100, Training Loss 0.000636\n",
      "Epoch 102, Training Loss 0.000428\n",
      "Epoch 104, Training Loss 0.000595\n",
      "Epoch 106, Training Loss 0.000254\n",
      "Epoch 108, Training Loss 0.000381\n",
      "Epoch 110, Training Loss 0.000435\n",
      "Epoch 112, Training Loss 0.000467\n",
      "Epoch 114, Training Loss 0.000481\n",
      "Epoch 116, Training Loss 0.000118\n",
      "Epoch 118, Training Loss 0.000418\n",
      "Epoch 120, Training Loss 0.000449\n",
      "Epoch 122, Training Loss 0.000574\n",
      "Epoch 124, Training Loss 0.000482\n",
      "Epoch 126, Training Loss 0.000359\n",
      "Epoch 128, Training Loss 0.000223\n",
      "Epoch 130, Training Loss 0.000432\n",
      "Epoch 132, Training Loss 0.000289\n",
      "Epoch 134, Training Loss 0.000254\n",
      "Epoch 136, Training Loss 0.000457\n",
      "Epoch 138, Training Loss 0.000250\n",
      "Epoch 140, Training Loss 0.000392\n",
      "Epoch 142, Training Loss 0.000397\n",
      "Epoch 144, Training Loss 0.000310\n",
      "Epoch 146, Training Loss 0.000109\n",
      "Epoch 148, Training Loss 0.000405\n",
      "Epoch 150, Training Loss 0.000858\n",
      "Epoch 152, Training Loss 0.000451\n",
      "Epoch 154, Training Loss 0.000219\n",
      "Epoch 156, Training Loss 0.000402\n",
      "Epoch 158, Training Loss 0.000471\n",
      "Epoch 160, Training Loss 0.000429\n",
      "Epoch 162, Training Loss 0.000150\n",
      "Epoch 164, Training Loss 0.000358\n",
      "Epoch 166, Training Loss 0.000396\n",
      "Epoch 168, Training Loss 0.000418\n",
      "Epoch 170, Training Loss 0.000153\n",
      "Epoch 172, Training Loss 0.000187\n",
      "Epoch 174, Training Loss 0.000354\n",
      "Epoch 176, Training Loss 0.000346\n",
      "Epoch 178, Training Loss 0.000452\n",
      "Epoch 180, Training Loss 0.000160\n",
      "Epoch 182, Training Loss 0.000230\n",
      "Epoch 184, Training Loss 0.000310\n",
      "Epoch 186, Training Loss 0.000193\n",
      "Epoch 188, Training Loss 0.000174\n",
      "Epoch 190, Training Loss 0.000204\n",
      "Epoch 192, Training Loss 0.000438\n",
      "Epoch 194, Training Loss 0.000115\n",
      "Epoch 196, Training Loss 0.000191\n",
      "Epoch 198, Training Loss 0.000295\n",
      "Epoch 200, Training Loss 0.000363\n",
      "Epoch 202, Training Loss 0.000328\n",
      "Epoch 204, Training Loss 0.000166\n",
      "Epoch 206, Training Loss 0.000275\n",
      "Epoch 208, Training Loss 0.000148\n",
      "Epoch 210, Training Loss 0.000257\n",
      "Epoch 212, Training Loss 0.000118\n",
      "Epoch 214, Training Loss 0.000246\n",
      "Epoch 216, Training Loss 0.000181\n",
      "Epoch 218, Training Loss 0.000545\n",
      "Epoch 220, Training Loss 0.000568\n",
      "Epoch 222, Training Loss 0.000282\n",
      "Epoch 224, Training Loss 0.000247\n",
      "Epoch 226, Training Loss 0.000123\n",
      "Epoch 228, Training Loss 0.000093\n",
      "Epoch 230, Training Loss 0.000208\n",
      "Epoch 232, Training Loss 0.000256\n",
      "Epoch 234, Training Loss 0.000231\n",
      "Epoch 236, Training Loss 0.000456\n",
      "Epoch 238, Training Loss 0.000160\n",
      "Epoch 240, Training Loss 0.000270\n",
      "Epoch 242, Training Loss 0.000270\n",
      "Epoch 244, Training Loss 0.000140\n",
      "Epoch 246, Training Loss 0.000283\n",
      "Epoch 248, Training Loss 0.000134\n",
      "Epoch 250, Training Loss 0.000140\n",
      "Epoch 252, Training Loss 0.000159\n",
      "Epoch 254, Training Loss 0.000154\n",
      "Epoch 256, Training Loss 0.000192\n",
      "Epoch 258, Training Loss 0.000063\n",
      "Epoch 260, Training Loss 0.000278\n",
      "Epoch 262, Training Loss 0.000147\n",
      "Epoch 264, Training Loss 0.000217\n",
      "Epoch 266, Training Loss 0.000093\n",
      "Epoch 268, Training Loss 0.000185\n",
      "Epoch 270, Training Loss 0.000140\n",
      "Epoch 272, Training Loss 0.000161\n",
      "Epoch 274, Training Loss 0.000213\n",
      "Epoch 276, Training Loss 0.000455\n",
      "Epoch 278, Training Loss 0.000080\n",
      "Epoch 280, Training Loss 0.000067\n",
      "Epoch 282, Training Loss 0.000140\n",
      "Epoch 284, Training Loss 0.000086\n",
      "Epoch 286, Training Loss 0.000120\n",
      "Epoch 288, Training Loss 0.000055\n",
      "Epoch 290, Training Loss 0.000333\n",
      "Epoch 292, Training Loss 0.000091\n",
      "Epoch 294, Training Loss 0.000160\n",
      "Epoch 296, Training Loss 0.000171\n",
      "Epoch 298, Training Loss 0.000118\n",
      "Training finished, took 13886.28s\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 300\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64, shuffle=True)\n",
    "\n",
    "import time\n",
    "training_1hidden_start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for img, label in train_loader:\n",
    "        batch_size = img.shape[0]\n",
    "        out = model2(img.view(batch_size,-1))\n",
    "        loss = loss_fn(out, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  #back propagation\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 2 == 0:\n",
    "            print('Epoch %d, Training Loss %f' % (epoch, float(loss)))\n",
    "            \n",
    "print('Training finished, took {:.2f}s'.format(time.time() - training_1hidden_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "843336fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model2.state_dict(), data_path + '1b.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d287194b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: %f 0.5633\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
    "shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model2(imgs.view(batch_size, -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\", correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9999f446",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8) # <1>\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8524cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Net()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64, shuffle=True)\n",
    "\n",
    "optimizer = optim.SGD(model3.parameters(), lr=1e-2)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14e375a9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7948\\3812129257.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mloss_train\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             )\n\u001b[1;32m--> 487\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 300\n",
    "\n",
    "training_1hidden_start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    loss_train = 0.0\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model3(imgs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_train += loss.item()\n",
    "        \n",
    "    if epoch % 2 == 0:\n",
    "        print('Epoch %d, Training Loss %f' % (epoch, loss_train/len(train_loader)))\n",
    "        \n",
    "print('Training finished, took {:.2f}s'.format(time.time() - training_1hidden_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d189113e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model trained on Google Colab\n",
    "model3 = Net()\n",
    "model3.load_state_dict(torch.load('2a.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e8b2879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.80\n",
      "Accuracy val: 0.61\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  # <1>\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
    "                total += labels.shape[0]  # <3>\n",
    "                correct += int((predicted == labels).sum())  # <4>\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "\n",
    "validate(model3, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7706e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
    "                               padding=1)\n",
    "        self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2,\n",
    "                               kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv3(out)), 2)\n",
    "        out = out.view(-1, 4 * 4 * self.n_chans1 // 2)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64e3b6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Net2()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64, shuffle=True)\n",
    "\n",
    "optimizer = optim.SGD(model4.parameters(), lr=1e-2)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76da0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 300\n",
    "\n",
    "import time\n",
    "training_1hidden_start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    loss_train = 0.0\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model4(imgs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_train += loss.item()\n",
    "        \n",
    "    if epoch % 2 == 0:\n",
    "        print('Epoch %d, Training Loss %f' % (epoch, loss_train/len(train_loader)))\n",
    "        \n",
    "print('Training finished, took {:.2f}s'.format(time.time() - training_1hidden_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f0459bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model trained on Google Colab\n",
    "model4 = Net2()\n",
    "model4.load_state_dict(torch.load('2b.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95a9053e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.83\n",
      "Accuracy val: 0.68\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  # <1>\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
    "                total += labels.shape[0]  # <3>\n",
    "                correct += int((predicted == labels).sum())  # <4>\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "\n",
    "validate(model4, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e4869d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
